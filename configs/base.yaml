common:
  # The number of historical images
  img_history_size: 2
  # The number of future actions to predict, by default 64
  action_chunk_size: 5
  # The number of cameras to be used in the model
  num_cameras: 1
  # Dimension for state/action, we use the same space for both state and action

  # model state_token_dim
  state_dim: 2

dataset:
  droid_cotrack_path: /mnt/data/yanghaoting/droid-label/droid-data/
  droid_molmo_sam2_path: /mnt/data/xurongtao/datasets/droid_molmo_sam2
  hoi4d_metadata_path: /mnt/data/xurongtao/datasets/datasets--JianZhangAI--hoi4d/HOI4D_metadata
  hoi4d_rgb_path: /mnt/data/xurongtao/datasets/datasets--JianZhangAI--hoi4d/HOI4D_release
  hoi4d_frame_selection_path: /mnt/data/xurongtao/datasets/hoi4d_frame
  maniskill_path: /mnt/data/xurongtao/datasets/datasets--JianZhangAI--waypoint/labeled_demo

  # How to fit the image size
  image_aspect_ratio: pad
  # Maximum number of language tokens
  tokenizer_max_length: 1024

model:
  # Config for condition adpators
  lang_adaptor: mlp2x_gelu
  img_adaptor: mlp2x_gelu
  state_adaptor: mlp3x_gelu
  lang_token_dim: 3584 #4096 #3584
  img_token_dim: 1152
  # Dim of action or proprioception vector
  # A `state` refers to an action or a proprioception vector
  state_token_dim: 2 #128
  # Config for RDT structure
  rdt:
    # 1B: num_head 32 hidden_size 2048
    hidden_size: 2048
    depth: 28
    # 170M model
    # hidden_size: 1024
    # depth: 14
    num_heads: 32
    cond_pos_embed_type: multimodal 
  # For noise scheduler
  noise_scheduler:
    type: ddpm
    num_train_timesteps: 1000
    num_inference_timesteps: 5
    beta_schedule: squaredcos_cap_v2  # Critical choice
    prediction_type: sample #epsilon
    clip_sample: False
  # For EMA (params averaging)
  # We do not use EMA currently
  ema:
    update_after_step: 0
    inv_gamma: 1.0
    power: 0.75
    min_value: 0.0
    max_value: 0.9999
